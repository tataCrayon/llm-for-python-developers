# 评估设计

简单来说：**需要先行设定chunk和评估数据集数据格式。**

评估是优化的基础，但是评估的步骤、指标、需求，应当在设计阶段就考虑好。

比如我们的系统核心目标是：
“判断用户当前的知识水平，然后基于这个水平进行问答和知识迁移的高效大模型应用。”

那么就需要做query分解， 要有一个Agent执行知识水平检索、进行multi query操作，生成能判断知识水平的问题，然后去RAG，检索向量数据库。
首先，由llm对用户的问题进行分析，判断需要去检索（RAG）哪些知识，也就是生成待检索的新query list。

特点是LLM会拆解用户query，生成符合检索要求的问题。

那么我们在chunk阶段，就需要考虑我们的分块是否能应对LLM拆解出来的query。

所以，我们chunk是需要和评估一起考虑的。

我们使用Ragas框架进行评估，框架可以生成测试数据集，所以，我们的chunk和评估指标需要一起设计。

# Step one:确认问题

首先，明确我们系统会面临什么类型的问题。

> 抽象类的多跳查询、复杂查询。

然后，我们的每一个chunk,能否被一个直接、简单、针对性强的问题精确地检索到？
这是评估Chunking质量的基础。

在这个系统中，就是chunk组合，是否能很好地回答一个经过系统优化/分解后的子问题？

## RAG面临的问题

从数据摄取到检索、生成的评估。

## LLM面临的问题

自动化ReACT问题，包括记忆、工具、调用循环等...

# 数据集设计

```json
{
  "question_id": "unique_id_001",
  "source_doc_id": "markdown_file_name.md",
  "source_chunk_id": "chunk_hash_or_index",
  "user_profile": {
    "assumed_knowledge_level": "Beginner",
    // 初学者 or Expert
    "goal": "了解光合作用的基本概念"
    // 模拟用户意图
  },
  "question": "植物是怎么自己做饭的？",
  // 模拟初学者可能会问的、比较口语化的问题
  "decomposed_questions": [
    // 理想的Query分解结果
    "什么是光合作用？",
    "光合作用需要哪些原料？",
    "光合作用的产物是什么？"
  ],
  "knowledge_assessment_questions": [
    // 理想的、用于判断知识水平的问题
    "你知道叶绿体是什么吗？",
    "光合作用和呼吸作用有什么区别？"
  ],
  "contexts": [
    // **Ground Truth** 的上下文，也就是最相关的原文片段
    "光合作用是植物、藻类和某些细菌利用光能，将二氧化碳和水转化为富能有机物（主要是糖类），并释放出氧气的过程。这个过程主要在植物细胞的叶绿体中进行。"
  ],
  "ground_truth": "植物通过一个叫做‘光合作用’的过程来为自己制造养分。它们利用太阳光作为能量，吸收空气中的二氧化碳和根部吸收的水分，在叶子里的叶绿体中把这些原料转化成糖分（就像它们的食物），同时还会释放出我们呼吸需要的氧气。"
  // 基于上面contexts的理想回答
}

```

为什么是这个格式？

user_profile: 模拟不同知识水平的用户，让生成的问题更多样化，也更贴近您的应用场景。
question: 原始的用户问题，用于评测RAG系统的入口。
decomposed_questions: 这是您流程中第一步（Query分解Agent）的理想输出。您可以用它来评测您的分解模块是否有效。
knowledge_assessment_questions: 这是您的知识水平判断Agent的理想输出，可以用来评测它生成的问题质量。
contexts: 这是最关键的部分，是RAG中Retriever（检索器）应该必须检索到的原文片段。这是计算 context_recall 和 context_precision
的基石。
ground_truth: 这是最终答案的黄金标准，用于计算 answer_relevancy 和 faithfulness 等指标。

## 用于生成测试数据集的Prompt设计



